\section{gesture\+Recognition}
\label{group__gestureRecognition}\index{gesture\+Recognition@{gesture\+Recognition}}


A module that recognizes in real-\/time gestures belonging to a predefined set using 3\+D\+H\+OF and H\+OG descriptors and linear S\+V\+Ms as classifiers.  


A module that recognizes in real-\/time gestures belonging to a predefined set using 3\+D\+H\+OF and H\+OG descriptors and linear S\+V\+Ms as classifiers. 

\hypertarget{group__gestureRecognitionStereo_intro_sec}{}\subsection{Description}\label{group__gestureRecognitionStereo_intro_sec}
This module is able to recognize different gestures that belong to a predefined pool. It is possible to save features and train new Support Vector Machines using libsvm. Right now we provide a file to recognize 6 gestures depicted in app/conf/supported\+\_\+actions\+\_\+easy.\+jpg. 3\+D\+H\+OF and H\+OG are used as descriptors. For further information\+:

"S. R. Fanello$\ast$, I. Gori$\ast$, G. Metta, F. Odone Keep It Simple And Sparse\+: Real-\/\+Time Action Recognition. Journal of Machine Learning Research (J\+M\+LR), 2013."\hypertarget{group__gestureRecognitionStereo_rpc_port}{}\subsection{Commands\+:}\label{group__gestureRecognitionStereo_rpc_port}
The commands sent as bottles to the module port /$<$mod\+Name$>$/rpc are described in the following\+:

{\bfseries R\+EC} ~\newline
format\+: \mbox{[}rec\mbox{]} ~\newline
action\+: the module starts to recognize any action that is being performed.

{\bfseries S\+A\+VE} ~\newline
format\+: \mbox{[}save\mbox{]} ~\newline
action\+: the module starts saving features on a .txt file located in the directory specified as out\+Dir in the Resource\+Finder.

{\bfseries S\+T\+OP} ~\newline
format\+: \mbox{[}stop\mbox{]} ~\newline
action\+: the module stops recognizing or saving.\hypertarget{group__gestureRecognitionStereo_lib_sec}{}\subsection{Libraries}\label{group__gestureRecognitionStereo_lib_sec}

\begin{DoxyItemize}
\item Y\+A\+RP libraries.
\item kinect-\/wrapper library.
\item Open\+CV library.
\end{DoxyItemize}\hypertarget{group__gestureRecognitionStereo_portsc_sec}{}\subsection{Ports Created}\label{group__gestureRecognitionStereo_portsc_sec}

\begin{DoxyItemize}
\item {\itshape /} $<$mod\+Name$>$/rpc remote procedure call. It always replies something.
\item {\itshape /} $<$mod\+Name$>$/scores this is the port where the module outputs the result of the recognition procedure.
\item {\itshape /} $<$mod\+Name$>$/images this port outputs an image containing the player, his skeleton joints and his hands segmented with two different colors.
\end{DoxyItemize}\hypertarget{group__gestureRecognitionStereo_parameters_sec}{}\subsection{Parameters}\label{group__gestureRecognitionStereo_parameters_sec}
The following are the options that are usually contained in the configuration file, which is gesture\+Recognition.\+ini\+:

--name {\itshape name} 
\begin{DoxyItemize}
\item specify the module name, which is {\itshape gesture\+Recognition} by default.
\end{DoxyItemize}

--dimension {\itshape dimension} 
\begin{DoxyItemize}
\item number of bins for the 3D histogram of flow. The final histogram will be dimension$\ast$dimension$\ast$dimension.
\end{DoxyItemize}

-- out\+Dir {\itshape out\+Dir} 
\begin{DoxyItemize}
\item folder where the features will be saved, if the save command is sent to the rpc port.
\end{DoxyItemize}

-- show\+Images {\itshape show\+Images} 
\begin{DoxyItemize}
\item if this is true, depth and skeleton will be visualized.
\end{DoxyItemize}

There is another configuration file that should be provided, called S\+V\+M\+Models.\+ini. It is the file that contains information on the S\+V\+Ms that have been trained on the gestures it is wanted to recognize. One example file is already provided, and it allows recognizing 6 gestures specified in the file app/conf/supported\+\_\+actions\+\_\+easy.\+jpg. Those gestures can also be used to play the All Gestures You Can game. For further information\+:

I. Gori, S. R. Fanello, G. Metta, F. Odone All Gestures You Can\+: A Memory Game Against A Humanoid Robot. In proceedings of I\+E\+E\+E-\/\+R\+AS International Conference on Humanoid Robots, 2012.

The parameters that should be present in the S\+V\+M\+Models.\+ini file are\+:

-- num\+Actions {\itshape num\+Actions} 
\begin{DoxyItemize}
\item in the group G\+E\+N\+E\+R\+AL, number of trained actions.
\end{DoxyItemize}

-- n\+Features {\itshape n\+Features} 
\begin{DoxyItemize}
\item in the group G\+E\+N\+E\+R\+AL. It is 2 if 3\+D\+H\+OF and H\+OG on the whole body are used. If also H\+O\+Gs on the two hands are used, this parameter should be equal to 4.
\end{DoxyItemize}

-- dictionary\+Size {\itshape dictionary\+Size} 
\begin{DoxyItemize}
\item in the group G\+E\+N\+E\+R\+AL. Not used for now. It is needed if a dictionary learning step has to be applied.
\end{DoxyItemize}

-- buffer\+Size {\itshape buffer\+Size} 
\begin{DoxyItemize}
\item in the group G\+E\+N\+E\+R\+AL. Number of frames to be evaluated at each step.
\end{DoxyItemize}

-- frame\+Feature\+Size {\itshape frame\+Feature\+Size} 
\begin{DoxyItemize}
\item in the group G\+E\+N\+E\+R\+AL. Size of the final frame descriptor.
\end{DoxyItemize}

For each action there is a group called A\+C\+T\+I\+O\+NX, where X is a number going from 1 to the number of trained actions. In each A\+C\+T\+I\+O\+NX group there should be the parameter w, which is a list of the coefficients of the trained S\+VM.\hypertarget{group__gestureRecognitionStereo_tested_os_sec}{}\subsection{Tested OS}\label{group__gestureRecognitionStereo_tested_os_sec}
Windows, Linux

\begin{DoxyAuthor}{Author}
Ilaria Gori, Sean Ryan Fanello 
\end{DoxyAuthor}
